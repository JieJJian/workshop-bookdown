[["index.html", "SWAG Workshops Repository Chapter 1 Introduction", " SWAG Workshops Repository UW Statistical Workshops and Applications Group September 23, 2022 Chapter 1 Introduction Welcome to the Github repository for the Statistical Workshops and Applications Group (SWAG)! Each workshop will be given its own chapter in this document, where the content for the workshop will be shared. These workshops will be more interactive than presentations or lectures  and each workshop will typically be accompanied by relevant R code. For the Fall 2022 term, we have planned four workshops spanning several topics: sampling-resampling methods (Oct. 6), the Bernstein-von Mises theorem (Oct. 19), variational inference (Nov. 10), and partially identified models (Dec. 1). "],["chapter2.html", "Chapter 2 Sampling-Resampling Methods 2.1 Introduction 2.2 Rejection Sampling 2.3 Sampling-Resampling Methods 2.4 Implementation of Sampling-Resampling Methods 2.5 Sampling-Resampling in Multiple Dimensions", " Chapter 2 Sampling-Resampling Methods Luke Hagar October 6, 2022 2.1 Introduction Welcome to the first workshop for the Statistical Workshops and Applications Group (SWAG)! This workshop discusses sampling-resampling methods, mainly in the context of Bayesian inference. 2.2 Rejection Sampling Before introducing sampling-resampling methods, we briefly discuss rejection sampling (Ripley 2009) along with its strengths and shortcomings. In what follows, we discuss the set up for our sampling scenario. Lets suppose we can easily generate a sample from a continuous density function \\(g(\\boldsymbol{\\theta})\\). We call this the proposal distribution. However, we want a sample from a density \\(h(\\boldsymbol{\\theta})\\) such that \\(g(\\boldsymbol{\\theta}) = 0\\) implies \\(h(\\boldsymbol{\\theta}) = 0\\) for all \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\). We have a positive function \\(f(\\boldsymbol{\\theta})\\) that is proportional to \\(h(\\boldsymbol{\\theta})\\). That is, \\(h(\\boldsymbol{\\theta}) = f(\\boldsymbol{\\theta})/\\int f(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}\\). For rejection sampling, we further suppose that there exists an identifiable constant \\(M &gt; 0\\) such that \\(f(\\boldsymbol{\\theta})/g(\\boldsymbol{\\theta}) \\le M\\) for all \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\). Lets reinforce this terminology with an example. In this example, we want to sample from \\(h(\\theta) = 12\\theta^2(1-\\theta)\\) for \\(0 &lt; \\theta &lt; 1\\). This is actually a \\(\\text{BETA}(3,2)\\) distribution. For this example, we let \\(f(\\theta) = h(\\theta)\\). We have that \\(f(\\theta) \\le 16/9\\) for all \\(0 &lt; \\theta &lt; 1\\). We can easily sample over the unit interval using the uniform density \\(U(0,1)\\). This corresponds to choosing \\(g(\\theta) = 1\\) for \\(0 &lt; \\theta &lt; 1\\). It follows that \\(f(\\boldsymbol{\\theta})/g(\\boldsymbol{\\theta}) \\le 16/9 = M\\) for all \\(0 &lt; \\theta &lt; 1\\). This scenario is visualized in Figure 2.1. ## compute f and g across the range of theta for plotting purposes theta &lt;- seq(0,1,by = 0.005) f &lt;- 12*theta^2*(1-theta) g &lt;- rep(1, length(theta)) M &lt;- 16/9 ## generate the plot and corresponding legend plot(theta, f, col = &quot;steelblue&quot;, type = &quot;l&quot;, ylab = &quot;Density&quot;, ylim = c(0,2.25), xlab = expression(theta)) lines(theta, M*g, lty = 2) legend(&quot;topright&quot;, c(&quot;f&quot;, &quot;M*g&quot;), col = c(&quot;steelblue&quot;, &quot;black&quot;), lty = c(1,2), bty = &quot;n&quot;) Figure 2.1: Visualization of rejection sampling functions We now introduce rejection sampling. This process is detailed in Algorithm 1. A sample of \\(\\boldsymbol{\\theta}\\) values accepted via Algorithm 1 is a sample from the density of interest \\(h(\\boldsymbol{\\theta})\\) (Ripley 2009). Algorithm 1 Generate \\(\\boldsymbol{\\theta}\\) from \\(g(\\boldsymbol{\\theta})\\). Generate \\(u \\sim U(0,1)\\). If \\(u \\le f(\\boldsymbol{\\theta})/(Mg(\\boldsymbol{\\theta}))\\), return \\(\\boldsymbol{\\theta}\\); otherwise return to Step 1. We now illustrate how to implement rejection sampling to generate 10000 observations from \\(h(\\boldsymbol{\\theta})\\) for this simple example. The results are visualized in Figure 2.2. ## initialize matrices for accepted and rejected theta values accept_mat &lt;- NULL; reject_mat &lt;- NULL ## set seed for reproducibility set.seed(1) stop &lt;- FALSE ## continue until 10000 points are accepted while (stop == FALSE){ ## generate a value from g: U(0,1) theta_temp &lt;- runif(1) ## generate u to decide whether to accept/reject u &lt;- runif(1) ## compute the values for f and g at this theta value f_temp &lt;- 12*theta_temp^2*(1-theta_temp) g_temp &lt;- 1 ## decide whether or not to accept point; ## we save the rejected points and &quot;u&quot; realizations for the plot if (u &lt;= f_temp/(M*g_temp)){ accept_mat &lt;- rbind(accept_mat, c(theta_temp,u)) if (nrow(accept_mat) &gt;= 10000){ stop &lt;- TRUE } } else{ reject_mat &lt;- rbind(reject_mat, c(theta_temp,u)) } } ## generate the plot and corresponding legend ## green points represent accepted (theta, u) combinations ## red points represent rejected (theta, u) combinations plot(theta, f, col = &quot;steelblue&quot;, type = &quot;l&quot;, ylab = &quot;M*u&quot;, ylim = c(0,2.25), xlab = expression(theta), lwd = 1.5) lines(theta, M*g, lty = 2, lwd = 1.5) legend(&quot;topright&quot;, c(&quot;f&quot;, &quot;M*g&quot;), col = c(&quot;steelblue&quot;, &quot;black&quot;), lty = c(1,2), bty = &quot;n&quot;) points(accept_mat[,1], M*accept_mat[,2], col = adjustcolor(&quot;seagreen&quot;,0.05), pch = 19) points(reject_mat[,1], M*reject_mat[,2], col = adjustcolor(&quot;firebrick&quot;,0.05), pch = 19) Figure 2.2: Visualization of rejection sampling with accepted points (green) and rejected points (red) The points in Figure 2.2 depict which \\(\\theta\\) values were accepted (green) and rejected (red) by rejection sampling. The resulting sample appears to come from the \\(\\text{BETA}(3,2)\\) distribution. We make two final remarks about rejection sampling that bear relevance to sampling-resampling methods. To implement rejection sampling, we must identify a constant \\(M &gt; 0\\) such that \\(f(\\boldsymbol{\\theta})/g(\\boldsymbol{\\theta}) \\le M\\) for all \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\). This choice for \\(M\\) is important. For this example, we could have chosen \\(M &gt; 16/9\\), but the sampling procedure would have been less efficient. Choosing \\(M &lt; 16/9\\) would have returned a sample that is not from the \\(\\text{BETA}(3,2)\\) distribution. We need to carefully consider the support of \\(h(\\boldsymbol{\\theta})\\) and \\(g(\\boldsymbol{\\theta})\\). Choosing \\(g(\\boldsymbol{\\theta})\\) to be \\(U(0.25, 0.75)\\) would not have been appropriate for this example. Choosing \\(g(\\boldsymbol{\\theta})\\) to be \\(U(-1, 1)\\) would be fine but less efficient. When using sampling-resampling methods, remark 1 is often not of concern. 2.3 Sampling-Resampling Methods 2.3.1 Overview of the Sampling-Importance-Resampling Algorithm We now discuss how to obtain an approximate sample from the density \\(h(\\boldsymbol{\\theta})\\) using a particular weighted sampling-resampling method, which is a variant of the bootstrap procedure (Efron 1982). This method was first formally proposed in Rubin (1987) and Rubin (1988) as the sampling-importance-resampling (SIR) algorithm. We introduce this procedure via Algorithm 2, which uses notation from Smith and Gelfand (1992). Algorithm 2 Generate \\(\\boldsymbol{\\theta}_i, ~ i = 1,...,n\\) from \\(g(\\boldsymbol{\\theta})\\). For each \\(\\boldsymbol{\\theta}_i\\), compute \\(\\omega_i = f(\\boldsymbol{\\theta}_i)/g(\\boldsymbol{\\theta_i})\\). Let \\(q_i = \\omega_i/\\sum_{j=1}^n\\omega_j\\) for \\(i = 1,...,n\\). Draw \\(\\{\\boldsymbol{\\theta}^*_1,..., \\boldsymbol{\\theta}^*_m\\}\\) from the discrete distribution over \\(\\{\\boldsymbol{\\theta}_1, ..., \\boldsymbol{\\theta}_n \\}\\) with replacement, where mass \\(q_i\\) is placed on \\(\\boldsymbol{\\theta}_i\\). Under several conditions, \\(\\boldsymbol{\\theta}^*\\) is approximately distributed according to \\(h(\\boldsymbol{\\theta})\\). Algorithm 2 returns approximate samples from \\(h(\\boldsymbol{\\theta})\\) when \\(n\\) is sufficiently large and \\(supp(h) \\subseteq supp(g)\\), where \\(supp()\\) refers to the support of a probability distribution. How large \\(n\\) must be depends on the extent to which \\(h(\\boldsymbol{\\theta})\\) resembles \\(g(\\boldsymbol{\\theta})\\). Moreover, \\(m\\) is typically smaller than \\(n\\); Rubin (1987) stated that specifying \\(m\\) and \\(n\\) such that their ratio \\(n/m\\) is at least 20 should be sufficient in most scenarios. When implementing this sampling-resampling procedure, we must still be mindful of the supports of \\(h(\\boldsymbol{\\theta})\\) and \\(g(\\boldsymbol{\\theta})\\). However, we do not need to identify a constant \\(M &gt; 0\\) such that \\(f(\\boldsymbol{\\theta})/g(\\boldsymbol{\\theta}) \\le M\\) for all \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\). We only require a function \\(g(\\boldsymbol{\\theta})\\) that we can readily sample from and a function \\(f(\\boldsymbol{\\theta})\\) that is proportional to our density of interest \\(h(\\boldsymbol{\\theta})\\). For Bayesian inference, we often want to sample from a posterior distribution of interest \\(\\pi(\\boldsymbol{\\theta}| \\boldsymbol{x})\\) for \\(\\boldsymbol{\\theta}\\) given observed data \\(\\boldsymbol{x}\\). Let \\(L()\\) be the likelihood function and \\(p()\\) be the prior for \\(\\boldsymbol{\\theta}\\). The posterior distribution communicates which values \\(\\boldsymbol{\\theta}\\) are plausible given the observed data and our prior beliefs. By Bayes Theorem, we have that \\[\\pi(\\boldsymbol{\\theta}| \\boldsymbol{x}) = \\frac{L(\\boldsymbol{\\theta}; \\boldsymbol{x})p(\\boldsymbol{\\theta})}{\\int L(\\boldsymbol{\\theta}; \\boldsymbol{x})p(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}} \\propto L(\\boldsymbol{\\theta}; \\boldsymbol{x})p(\\boldsymbol{\\theta}).\\] Thus, we have \\(h(\\boldsymbol{\\theta}) = \\pi(\\boldsymbol{\\theta}| \\boldsymbol{x})\\) and \\(f(\\boldsymbol{\\theta}) = L(\\boldsymbol{\\theta}; \\boldsymbol{x})p(\\boldsymbol{\\theta})\\) using the notation from earlier. For a given \\(\\boldsymbol{\\theta}\\) value, it is straightforward to compute \\(f(\\boldsymbol{\\theta})\\); however, we are often not able to compute \\(h(\\boldsymbol{\\theta})\\) directly. As such, the SIR algorithm goes well with the framework for Bayesian inference. It can be used to generate an approximate sample from the posterior distribution of interest \\(h(\\boldsymbol{\\theta}) = \\pi(\\boldsymbol{\\theta}| \\boldsymbol{x})\\) and serves as an alternative to more standard Markov chain Monte Carlo (MCMC) methods in many scenarios. The SIR algorithm can be used with non-Bayesian methods, but the remainder of this workshop focuses on implementing the SIR algorithm to conduct approximate posterior sampling. 2.3.2 Computational Considerations The SIR algorithm often produces more stable results when \\(\\omega_i, i = 1,...,n\\) are computed on the logarithmic scale. This is consistent with other methods for Bayesian inference that do not involve sampling-resampling. Particularly when \\(\\boldsymbol{\\theta}\\) is multivariate, \\(f(\\boldsymbol{\\theta})\\) and \\(g(\\boldsymbol{\\theta})\\) can take small positive values that are extremely close to 0. Computing \\(\\text{log}(\\omega_i)\\) helps make underflow errors less common, as we will see shortly. We have that \\[\\text{log}(\\omega_i) = \\text{log}(f(\\boldsymbol{\\theta}_i)) - \\text{log}(g(\\boldsymbol{\\theta}_i)).\\] In the context of Bayesian inference, \\(f(\\boldsymbol{\\theta}) = L(\\boldsymbol{\\theta}; \\boldsymbol{x})p(\\boldsymbol{\\theta})\\) is generally the product of several terms, so \\(\\text{log}(f(\\boldsymbol{\\theta}_i))\\) is often easier to manipulate than \\(f(\\boldsymbol{\\theta}_i)\\). When \\(g(\\boldsymbol{\\theta})\\) is a well known probability distribution, we can often compute \\(\\text{log}(g(\\boldsymbol{\\theta}_i))\\) using built-in R functions. For instance, if \\(g(\\boldsymbol{\\theta})\\) is the standard normal distribution, we can compute \\(\\text{log}(g(\\boldsymbol{\\theta}_i))\\) as \\(\\texttt{dnorm(}\\boldsymbol{\\theta}_i\\texttt{, log = TRUE)}\\). We must then exponentiate the \\(\\text{log}(\\omega_i)\\) values to compute the normalized weights \\(q_i, ~ i = 1, ..., n\\). In certain situations, we proceed with caution to avoid more underflow errors. Lets consider the following example with only three \\(\\text{log}(\\omega_i)\\) values: \\(\\text{log}(\\omega_1) = 0\\), \\(\\text{log}(\\omega_2) = 1\\), and \\(\\text{log}(\\omega_3) = 2\\). For this example, we can exponentiate and standardize these weights without issues using the following R code. ## define log weights log_omega &lt;- c(0, 1, 2) ## exponentiate the weights omega &lt;- exp(log_omega) ## standardize the weights and print results by enclosing assignment command with () (q &lt;- omega/sum(omega)) ## [1] 0.09003057 0.24472847 0.66524096 Here, we standardize the weights after exponentiation. That being the case, we can apply a translation to the weights on the logarithmic scale without impacting the final standardized weights. For this example, the maximum \\(\\text{log}(\\omega_i)\\) is \\(\\text{log}(\\omega_3) = 2\\). Lets subtract 2 from each original \\(\\text{log}(\\omega_i)\\) value before exponentiation and output the results. ## define log weights log_omega &lt;- c(0, 1, 2) ## subtract 2 from each log_omega value and exponentiate the weights omega &lt;- exp(log_omega - max(log_omega)) ## standardize the weights (q &lt;- omega/sum(omega)) ## [1] 0.09003057 0.24472847 0.66524096 The final standardized weights are the same! This trick is useful when the \\(\\text{log}(\\omega_i)\\) values are very small (or very large). Lets now imagine that \\(\\text{log}(\\omega_1) = -800\\), \\(\\text{log}(\\omega_2) = -799\\), and \\(\\text{log}(\\omega_3) = -798\\). Lets see what occurs if we try to exponentiate these values. ## define log weights log_omega &lt;- c(-800, -799, -798) ## exponentiate the weights (omega &lt;- exp(log_omega)) ## [1] 0 0 0 ## standardize the weights (q &lt;- omega/sum(omega)) ## [1] NaN NaN NaN This produces an underflow error. The values for \\(\\omega_i, ~ i = 1, 2, 3\\) are so small that they are rounded down to 0. But, we can apply a translation to the \\(\\text{log}(\\omega_i)\\) values by subtracting \\(\\text{max}_{i = 1, 2, 3}~\\text{log}(\\omega_i) = -798\\) from each value. This produces the same final standardized weights as for the earlier example  which makes sense because this example simply subtracted 800 from each of the earlier \\(\\text{log}(\\omega_i)\\) values. ## define log weights log_omega &lt;- c(-800, -799, -798) ## subtract max(log_omega) from each log_omega value and exponentiate the weights omega &lt;- exp(log_omega - max(log_omega)) ## standardize the weights (q &lt;- omega/sum(omega)) ## [1] 0.09003057 0.24472847 0.66524096 2.4 Implementation of Sampling-Resampling Methods 2.4.1 Illustrative Example with Binary Data Here, we demonstrate how to implement the SIR algorithm to faciliate posterior sampling for a simple example. In this example, we assume that we observe binary data \\(x_1, ..., x_N\\) such that \\(x_j \\sim \\text{BIN}(1, \\theta)\\). We assume that the prior for \\(\\theta\\) is an uninformative \\(\\text{BETA}(1,1)\\) prior, which implies that \\(p(\\theta) = 1\\) for \\(0 &lt; \\theta &lt; 1\\). In this case, the posterior \\(h(\\theta) = \\pi(\\theta| \\boldsymbol{x})\\) is such that \\[h(\\boldsymbol{\\theta}) \\propto L(\\theta; \\boldsymbol{x}) = \\prod_{j=1}^N\\theta^{x_j}(1 - \\theta)^{1-x_j} = \\theta^{\\sum_{j=1}^Nx_j}(1-\\theta)^{N-\\sum_{j=1}^Nx_j} = f(\\theta).\\] Lets assume that we have \\(N = 20\\) observations and that 15 of these Bernoulli trials were successful (\\(\\sum_{j=1}^N x_j = 15\\)). It follows that \\(f(\\theta) = \\theta^{15}(1-\\theta)^5\\) for \\(0 &lt; \\theta &lt; 1\\). For this example, \\(h(\\theta)\\) is actually known: it is a \\(\\text{BETA}(16, 6)\\) distribution. Therefore, we do not need to use sampling-resampling methods to sample from \\(h(\\boldsymbol{\\theta})\\). However, because \\(h(\\theta)\\) is known, we can use this example to explore the performance of the SIR algorithm for different proposal distributions \\(g(\\boldsymbol{\\theta})\\). The first proposal distribution that we consider is \\(g(\\theta) = 1\\) for \\(0 &lt; \\theta &lt; 1\\) (i.e., the \\(U(0,1)\\) distribution). We plot \\(h(\\theta)\\) and \\(g(\\theta)\\) in Figure 2.3. ## compute h and g across the range of theta for plotting purposes theta &lt;- seq(0,1,by = 0.005) h &lt;- dbeta(theta, 16, 6) g &lt;- rep(1, length(theta)) ## generate the plot and corresponding legend plot(theta, h, col = &quot;steelblue&quot;, type = &quot;l&quot;, ylab = &quot;Density&quot;, ylim = c(0,4.5), xlab = expression(theta)) lines(theta, g, lty = 2) legend(&quot;topright&quot;, c(&quot;h&quot;, &quot;g&quot;), col = c(&quot;steelblue&quot;, &quot;black&quot;), lty = c(1,2), bty = &quot;n&quot;) Figure 2.3: Visualization of posterior and uniform sampling function While \\(h(\\theta)\\) and \\(g(\\theta)\\) have the same support, it does not appear that \\(U(0,1)\\) will be a very efficient proposal distribution for this example. Values of \\(\\theta_i\\) close to 0 that are generated via \\(g(\\theta)\\) will be assigned standardized weights of \\(q_i \\approx 0\\). We now show how to implement the entire SIR algorithm for this example with the uniform sampling function. We use the settings \\(n\\) = 1 million and \\(m = 50000\\). The results are visualized in Figure 2.4. ## input the sample of 20 observations into R x &lt;- c(rep(1,15), rep(0,5)) ## extract the number of observations (N) and successes N &lt;- length(x); sum_x &lt;- sum(x) ## define SIR algorithm settings n &lt;- 1000000; m &lt;- 50000 ## define a function that is proportional to the posterior (on the logarithmic scale) propLog &lt;- function(theta, obs, sum_data){ ## return -Inf is theta is not between 0 and 1 (this will exponentiate to give q_i = 0) return(ifelse(theta &gt; 0 &amp; theta &lt; 1, sum_data*log(theta) + (obs - sum_data)*log(1-theta), -Inf)) } set.seed(2) ## sample from proposal distribution samp &lt;- runif(n) ## form importance sampling weights on log-scale; ## here, log(g(theta)) = log(1) = 0 for all 0 &lt; theta &lt; 1 w1 &lt;- propLog(samp, N, sum_x) - 0 w1 &lt;- exp(w1 - max(w1)) q1 &lt;- w1/sum(w1) ## resample to create approximate sample from posterior inds1 &lt;- sample(seq(1,n,by = 1), size = m, replace = TRUE, prob = q1) post1 &lt;- samp[inds1] ## generate the plot and corresponding legend hist(post1, col = adjustcolor(&quot;grey50&quot;, 0.15), main = &quot;&quot;, freq = FALSE, xlim = c(0.2,1), xlab = expression(theta), ylab = &quot;Density&quot;, ylim = c(0, 4.5)) lines(theta, h, col = &quot;steelblue&quot;, type = &quot;l&quot;) lines(theta, g, lty = 2) legend(&quot;topright&quot;, c(&quot;h&quot;, &quot;g&quot;), col = c(&quot;steelblue&quot;, &quot;black&quot;), lty = c(1,2), bty = &quot;n&quot;) Figure 2.4: Histogram of posterior sample 1 obtained using SIR (with densities for \\(h\\) and \\(g\\)) The uniform proposal distribution appears to be serviceable for this example. The density curve for \\(h(\\theta)\\)  which is not known exactly in most situations  agrees well with histogram of the approximate posterior sample. However, the simulation results confirm that this distribution is not very efficient. The histogram of the standardized weights for this simulation is given in Figure 2.5. ## generate the plot and corresponding legend hist(q1, col = adjustcolor(&quot;grey50&quot;, 0.15), main = &quot;&quot;, xlab = expression(q), ylab = &quot;Frequency&quot;) Figure 2.5: Histogram of standardized weights from SIR algorithm (uniform proposal) If we were to use \\(h(\\theta)\\) as the proposal, all weights should be equal to \\(n^{-1} = 1000000^{-1} = 1 \\times 10^{-6}\\). In Figure 2.5, we can see that many of the standarized weights are extremely close to 0, and these \\(\\theta\\) values are very unlikely to be selected during the weighted sampling process. In contrast, some of the weights are more than 4 times greater than \\(1 \\times 10^{-6}\\). If we do not generate many points from \\(g(\\theta)\\) (\\(n\\) is small), then our posterior sample may not have many unique points. This issue can be overcome by generating a very large sample of points from the proposal distribution. We now discuss other potential choices for the proposal distribution for this example. 2.4.2 Practical Considerations for Choosing Proposal Distributions Diffuse distributions that are easy to sample from are often popular choices for proposal distributions. In particular, the uniform and normal distributions are often parameterized appropriately to serve this purpose. There are adaptive extensions to the SIR algorithm, including those by West (1993) and Givens and Raftery (1996). These methods typically specify a diffuse proposal distribution to obtain an initial sample from \\(h(\\boldsymbol{\\theta})\\). This initial sample from \\(h(\\boldsymbol{\\theta})\\) then informs a better proposal distribution and the SIR algorithm is run again. This process is repeated as necessary. We do not discuss these methods further in this workshop; we focus on the case where an approximate sample is obtained by running the SIR algorithm one time with a given proposal distribution. We now show how to implement the SIR algorithm for this example with the normal proposal density \\(N(0.75, 0.15)\\), where \\(0.15\\) is the standard deviation. We discuss why this is an appropriate proposal distribution shortly. The results are visualized in Figure 2.6. set.seed(3) ## define parameters for proposal distribution mu_g &lt;- 0.75 sigma_g &lt;- 0.15 ## sample from proposal distribution samp &lt;- rnorm(n, mu_g, sigma_g) ## form importance sampling weights on log-scale; w2 &lt;- propLog(samp, N, sum_x) - dnorm(samp, mu_g, sigma_g, log = TRUE) w2 &lt;- exp(w2 - max(w2)) q2 &lt;- w2/sum(w2) ## resample to create approximate sample from posterior inds2 &lt;- sample(seq(1,n,by = 1), size = m, replace = TRUE, prob = q2) post2 &lt;- samp[inds2] ## generate the plot and corresponding legend hist(post2, col = adjustcolor(&quot;grey50&quot;, 0.15), main = &quot;&quot;, freq = FALSE, xlim = c(0.2,1), xlab = expression(theta), ylab = &quot;Density&quot;, ylim = c(0, 4.5)) lines(theta, h, col = &quot;steelblue&quot;, type = &quot;l&quot;) lines(theta, dnorm(theta, mu_g, sigma_g), lty = 2) legend(&quot;topright&quot;, c(&quot;h&quot;, &quot;g&quot;), col = c(&quot;steelblue&quot;, &quot;black&quot;), lty = c(1,2), bty = &quot;n&quot;) Figure 2.6: Histogram of posterior sample 2 obtained using SIR (with densities for \\(h\\) and \\(g\\)) We can see the \\(N(0.75, 0.15)\\) proposal distribution performs well for this example. The density curve for \\(h(\\theta)\\) coincides with histogram of the approximate posterior sample. We can see that the density curve for this proposal distribution \\(g(\\theta)\\) resembles the posterior of interest \\(h(\\theta)\\) more than the uniform proposal distribution. In fact, the modes of \\(h(\\theta)\\) and \\(g(\\theta)\\) are the same: 0.75. We note that the support of the normal distribution is not restricted to the unit interval. However, this is not a problem. The \\(\\theta_i\\) values generated via \\(g(\\theta)\\) such that \\(\\theta_i \\notin (0,1)\\) are assigned standardized sampling weights of \\(q_i = 0\\). The histogram of the standardized weights for this simulation, given in Figure 2.7, suggests that this proposal distribution is more efficient than the previous one: the standardized weights take values closer to \\(1 \\times 10^{-6}\\) than for the previous example. We discuss numerical methods to compare proposal distributions in the next subsection. ## generate the plot and corresponding legend hist(q2, col = adjustcolor(&quot;grey50&quot;, 0.15), main = &quot;&quot;, xlab = expression(q), ylab = &quot;Frequency&quot;) Figure 2.7: Histogram of standardized weights from SIR algorithm (normal proposal 1) We now explore what occurs when we implement the SIR algorithm for this example with an inappropriate proposal distribution. We choose the normal proposal density \\(N(0.85, 0.05)\\), where \\(0.05\\) is the standard deviation. We discuss why this is not an appropriate proposal distribution shortly. The results are visualized in Figure 2.8. set.seed(5) ## define parameters for proposal distribution mu_g &lt;- 0.85 sigma_g &lt;- 0.05 ## sample from proposal distribution samp &lt;- rnorm(n, mu_g, sigma_g) ## form importance sampling weights on log-scale; w3 &lt;- propLog(samp, N, sum_x) - dnorm(samp, mu_g, sigma_g, log = TRUE) w3 &lt;- exp(w3 - max(w3)) q3 &lt;- w3/sum(w3) ## resample to create approximate sample from posterior inds3 &lt;- sample(seq(1,n,by = 1), size = m, replace = TRUE, prob = q3) post3 &lt;- samp[inds3] ## generate the plot and corresponding legend hist(post3, col = adjustcolor(&quot;grey50&quot;, 0.15), main = &quot;&quot;, freq = FALSE, xlim = c(0.2,1), xlab = expression(theta), ylab = &quot;Density&quot;, ylim = c(0, 8)) lines(theta, h, col = &quot;steelblue&quot;, type = &quot;l&quot;) lines(theta, dnorm(theta, mu_g, sigma_g), lty = 2) legend(&quot;topright&quot;, c(&quot;h&quot;, &quot;g&quot;), col = c(&quot;steelblue&quot;, &quot;black&quot;), lty = c(1,2), bty = &quot;n&quot;) Figure 2.8: Histogram of posterior sample 3 obtained using SIR (with densities for \\(h\\) and \\(g\\)) We can see the \\(N(0.85, 0.05)\\) proposal distribution does not perform well for this example. The density curve for \\(h(\\theta)\\) deviates histogram of the approximate posterior sample. Although the support for \\(g(\\theta)\\) is \\(\\theta \\in \\mathbb{R}\\), \\(g(\\theta)\\) is practically 0 for \\(\\theta &lt; 0.6\\). It is extremely unlikely that we will sample \\(\\theta\\) values less than 0.6 for finite \\(n\\), and they will not appear in the final sample. In practice, we do not know \\(h(\\theta)\\), so we cannot compare the distribution of the sample to the density of \\(h(\\theta)\\). However, we can compare the distribution of the approximate posterior sample to the proposal \\(g(\\theta)\\). We can see that many of the \\(\\theta\\) values in our sample correspond to extreme values of the proposal distribution \\(g(\\theta)\\); this suggests that the proposal distribution may not be diffuse enough. If \\(\\boldsymbol{\\theta}\\) is multivariate, then we could compare low dimensional projections of the sample distribution and \\(g(\\boldsymbol{\\theta})\\). ## return maximum standardized weight (max(q3)) ## [1] 0.01455077 The maximum standardized weight for this simulation is 0.01455. This is 14550 times larger than \\(1 \\times 10^{-6}\\), which indicates that the proposal distribution does not resemble the density of interest \\(h(\\theta)\\) very much. 2.4.3 Comparing Proposal Distributions Here, we consider two numerical metrics to evaluate the suitability of the proposal distribution that are presented in Givens and Raftery (1996). If the typically unknown \\(h(\\boldsymbol{\\theta})\\) were used as a proposal distribution, all standardized sampling weights would take a value of \\(1 \\times 10^{-6}\\). When most sampling weights take values close to \\(1 \\times 10^{-6}\\), our final approximate sample of size \\(m\\) should contain many unique points. That is, our sample should not be comprised of several points that are each selected many times. We let \\(Q\\) be the number of unique points in our final sample of \\(m\\) values. When all sampling weights are constant (i.e., equal to \\(1/n\\)), then \\(\\mathbb{E}(Q) \\approx n(1- \\text{exp}(-m/n))\\). We then define \\[U = \\frac{Q}{n(1- \\text{exp}(-m/n))}.\\] \\(U\\) generally takes values between 0 and 1. We note that \\(U\\) can take values of greater than 1, particularly when the proposal density closely resembles \\(h(\\boldsymbol{\\theta})\\). However, this is not likely to be the case when \\(g(\\boldsymbol{\\theta})\\) and \\(h(\\boldsymbol{\\theta})\\) differ substantially. Generally, larger values of \\(U\\) are preferred. We now compute the \\(U\\) values for each of the three proposal densities considered for this illustrative example: \\(U(0,1)\\), \\(N(0.75, 0.15)\\), and \\(N(0.85, 0.05)\\). ## compute denominator for U (number of m = 50000 points expected to be unique under proposal h) (denom &lt;- n*(1- exp(-m/n))) ## [1] 48770.58 ## compute U for U(0,1) (u1 &lt;- round(length(unique(inds1))/denom,4)) ## [1] 0.9511 ## compute U for N(0.75, 0.15) (u2 &lt;- round(length(unique(inds2))/denom,4)) ## [1] 0.9943 ## compute U for N(0.85, 0.05) (u3 &lt;- round(length(unique(inds3))/denom,4)) ## [1] 0.6875 The \\(U\\) values are 0.9511 for \\(U(0,1)\\), 0.9943 for \\(N(0.75, 0.15)\\), and 0.6875 for \\(N(0.85, 0.05)\\). The \\(N(0.75, 0.15)\\) proposal distribution has the largest \\(U\\) value, which agrees with informal insights drawn from the histograms of the standardized sampling weights. Similarly, we could also consider the mean squared distance between \\(n\\) times the standardized sampling weights and 1. To this end, we let \\[D = n^{-1}\\sum_{i=1}^n(n\\times q_i - 1)^2 = n\\sum_{i=1}^n(q_i - n^{-1})^2,\\] where \\(n\\) = 1 million for this example. This metric \\(D\\) penalizes proposal densities that give rise to situations where a few small regions of its support yield extremely large standardized sampling weights. Generally, smaller values of \\(D\\) are preferred. We now compute the \\(D\\) values for each of the three proposal densities considered for this illustrative example. ## compute D for U(0,1) (d1 &lt;- round(n*sum((q1 - 1/n)^2),3)) ## [1] 2.046 ## compute D for N(0.75, 0.15) (d2 &lt;- round(n*sum((q2 - 1/n)^2),3)) ## [1] 0.291 ## compute D for N(0.85, 0.05) (d3 &lt;- round(n*sum((q3 - 1/n)^2),3)) ## [1] 658.621 The \\(D\\) values are 2.046 for \\(U(0,1)\\), 0.291 for \\(N(0.75, 0.15)\\), and 658.621 for \\(N(0.85, 0.05)\\). The \\(N(0.75, 0.15)\\) proposal distribution has the smallest \\(D\\) value. Givens and Raftery (1996) suggested comparing competing proposal distributions using the ratio of their D values. In this case, the \\(N(0.75, 0.15)\\) proposal is about 7 times better than the \\(U(0,1)\\) proposal. 2.5 Sampling-Resampling in Multiple Dimensions 2.5.1 Exercise with Illustrative Example We now briefly consider how to implement the SIR algorithm for a multivariate example. In this example, we assume that we observe data \\(x_1, x_2 &gt;0\\). Here, we assume that \\(\\boldsymbol{\\theta} = (\\alpha, \\beta)^T\\) for \\(0 &lt; \\alpha &lt; 1\\) and \\(0 &lt; \\beta &lt; 1\\). We independently assume a \\(U(0,1)\\) prior for \\(\\alpha\\) and \\(\\beta\\), which implies that \\(p(\\alpha, \\beta) = 1\\) for \\(0 &lt; \\alpha, \\beta &lt; 1\\). In this case, the posterior \\(h(\\alpha, \\beta) = \\pi(\\alpha, \\beta| \\boldsymbol{x})\\) is proportional to the likelihood function that we define below: \\[h(\\alpha, \\beta) \\propto L(\\alpha, \\beta; \\boldsymbol{x}) = \\alpha(1-\\alpha)\\beta(1-\\beta)\\text{exp}(-x_1\\alpha -\\beta^{x_2}) = f(\\alpha,\\beta).\\] Lets assume that we observe \\(x_1 = 3\\) and \\(x_2 = 5\\) We will use the prior \\(p(\\alpha, \\beta) = 1\\) for \\(0 &lt; \\alpha, \\beta &lt; 1\\) as the proposal density \\(g(\\alpha, \\beta)\\). You can complete the following code block to generate a contour plot of the posterior sample, depicted in Figure 2.9. A helper function is provided to compute \\(\\text{log}(f(\\alpha, \\beta))\\). In general, it can be more difficult to chose proposal densities for multivariate posteriors of interest, especially when the support is unbounded. Adaptive sampling-resampling methods can be quite useful in these situations. Moreover, we generally require larger values for \\(n\\) and \\(m\\) used with the SIR algorithm when the domain over which we want to sample is multivariate. ## define SIR algorithm settings n &lt;- 2500000; m &lt;- 125000 ## define a function that is proportional to the posterior (on the logarithmic scale) propLog &lt;- function(alpha, beta){ return(log(alpha) + log(1-alpha) + log(beta) + log(1-beta) - 3*alpha - beta^5) } set.seed(6) ## sample from proposal distribution (for alpha and beta) samp_alpha &lt;- runif(n) samp_beta &lt;- runif(n) ## form importance sampling weights on log-scale w &lt;- propLog(samp_alpha, samp_beta) w &lt;- exp(w - max(w)) q &lt;- w/sum(w) ## resample to create approximate sample from posterior inds &lt;- sample(seq(1,n,by = 1), size = m, replace = TRUE, prob = q) post_alpha &lt;- samp_alpha[inds] post_beta &lt;- samp_beta[inds] library(MASS) ## generate a contour plot for posterior den &lt;- kde2d(x=post_alpha, y=post_beta, n = 100) zlim &lt;- range(den$z) contour(den$x, den$y, den$z, col=&quot;grey10&quot;, xlim = c(0,1), ylim = c(0,1), levels = pretty(zlim, 10), lwd=1, xlab = expression(alpha), ylab = expression(beta)) Figure 2.9: Contour plot of posterior sample obtained using SIR for multivariate example "],["bernstein-von-mises-theorem.html", "Chapter 3 Bernstein-von Mises Theorem 3.1 Introduction 3.2 Theorem 3.3 Limitations", " Chapter 3 Bernstein-von Mises Theorem Augustine Wigle 3.1 Introduction The Bernstein-von Mises theorem (or BVM theorem) connects Bayesian and frequentist inference. In this workshop, we will state the theorem, talk about its importance, and touch on some of the required assumptions. We will work through some examples in R which let us visualize the theorem, and finally, we will talk about violations of the assumptions. This workshop is intended to introduce you to the theorem and encourage you to consider when it applies. It is not a rigourous treatment of the theorem - for those interested in the more technical details, we recommend Van der Vaart (2000) and Kleijn and Van der Vaart (2012). In this section we will give a brief review of Bayesian inference, the posterior distribution, and credible intervals. 3.1.1 Bayesian Inference Since this theorem applies to Bayesian models, we will give a quick review of Bayesian inference. In Bayesian inference, our state of knowledge about anything unknown is described by a probability distribution. Bayesian statistical conclusions about a parameter \\(\\theta\\) are made in terms of probabilistic statements conditional on the observed data \\(y\\). The distribution of interest is therefore \\(p(\\theta \\mid y)\\), the posterior distribution. We first specify a model which provides the joint probability distribution, that is, \\(p(\\theta, y) = p(\\theta)p(y\\mid \\theta)\\), where \\(p(\\theta)\\) is the prior distribution, which describes prior beliefs about the parameter(s) \\(\\theta\\), and \\(p(y\\mid \\theta)\\) is the data distribution of the likelihood. Then, Bayes theorem shows how to obtain the posterior distribution: \\[\\begin{equation*} p(\\theta \\mid y) = \\frac{p(\\theta)p(y\\mid \\theta)}{p(y)} \\end{equation*}\\] In most models, \\(p(\\theta\\mid y)\\) does not have a known parametric form and computational methods are required to overcome this problem, such as Markov Chain Monte Carlo (MCMC), or sampling-resampling techniques, covered in Chapter 2. In some special cases of likelihood and prior distribution combinations, the posterior can be determined analytically. These are called conjugate models. In the examples throughout this workshop, we will use conjugate models to avoid the need for fancy sampling techniques. Point estimates for \\(\\theta\\) can be derived from the posterior distribution, for example, by taking the posterior median or mean. Credible intervals are the Bayesian version of confidence intervals. A credible interval of credibility level \\(100\\times(1-\\alpha)\\) are defined as sets where the posterior probability of \\(\\theta\\) in the set is \\(100\\times(1-\\alpha)\\) and can be obtained in a variety of ways, such as by taking the lower and upper \\(\\alpha/2\\) quantiles of the posterior distribution. 3.2 Theorem A succinct statement of the theorem is as follows (for a more detailed and technical statement and proof, see Van der Vaart (2000)): Theorem 3.1 Under certain assumptions, a posterior distribution converges to a multivariate normal distribution centred at the maximum likelihood estimate \\(\\hat \\theta\\) and with covariance matrix given by \\(n^{-1}I(\\theta_0)^{-1}\\) as the sample size \\(n \\rightarrow \\infty\\) , where \\(\\theta_0\\) is the true population parameter and \\(I(\\theta_0)\\) is the Fisher information matrix evaluated at \\(\\theta_0\\). Or in other words, as you get more data, the posterior looks more and more like the sampling distribution of the MLE (if the assumptions are satisfied). 3.2.1 Importance The BVM theorem is useful because it provides a frequentist justification for Bayesian inference. The main takeaway of the theorem is that Bayesian inference is asymptotically correct from a frequentist perspective. In particular, Bayesian credible intervals are asymptotically confidence intervals. Another way to think about the theorems interpretation is that the influence of the prior disappears and the posterior becomes normal once you observe enough data. This is analogous to a pure frequentist approach where there is no prior information and the sampling distribution of the MLE becomes normal as you observe more and more data. 3.2.2 Required Assumptions Of course, for the theorem to hold, we require several assumptions to be satisfied. We are only going to touch on some of the more important conditions and we will not go into the technical details for this workshop (for technical details see Van der Vaart (2000)). Some of the more important assumptions are: The log-likelihood is smooth The MLE is consistent The prior distribution has non-zero density in a neighborhood of the true value \\(\\theta_0\\) The true parameter value is on the interior of the parameter space The model has a finite and fixed number of parameters We will discuss when some of these conditions may be violated and see some examples. We will start with an example where this theorem holds! 3.2.3 Example 1 - Normal-normal model Lets consider a nice example: we observe \\(Y_1, \\dots, Y_n\\) from a \\(N(\\theta, 1)\\) distribution. We are interested in estimating \\(\\theta\\). Lets also suppose that the true value of \\(\\theta\\) is 0. Bayesian Approach We will use a normal prior for \\(\\theta\\), that is, \\(\\theta \\sim N(0,1)\\). This is actually an example of a conjugate distribution and so there is an analytical solution for the posterior, which will make plotting the solution very convenient: \\[\\begin{equation*} \\theta \\mid Y_1, \\dots, Y_n \\sim N(\\frac{\\sum_{i=1}^n Y_i}{n+1}, \\frac{1}{n + 1}). \\end{equation*}\\] Frequentist Approach The MLE of \\(\\theta\\) is the sample mean, \\(\\hat\\theta = \\sum_{i=1}^nY_i/n\\) and the Fisher information is \\(1\\). The sampling distribution of \\(\\hat \\theta\\) is \\[\\begin{equation*} \\hat \\theta\\sim N(0, \\frac{1}{n}). \\end{equation*}\\] Lets look at what happens as we observe more and more data in R. # Set true param value theta_true &lt;- 0 # Functions to calculate the posterior mean and sd post_mean &lt;- function(x) { n &lt;- length(x) sum(x)/(n+1) } post_sd &lt;- function(x) { n &lt;- length(x) sqrt(1/(n+1)) } # Function to calculate asymptotic sd for MLE mle_sd &lt;- function(x) { sqrt(1/length(x)) } # Generate some data of different sample sizes set.seed(2022) y_small &lt;- rnorm(10, mean = theta_true, sd = 1) y_med &lt;- rnorm(50, mean = theta_true, sd = 1) y_large &lt;- rnorm(100, mean = theta_true, sd = 1) # Set up Plotting x_vals &lt;- seq(-1, 1, by = 0.01) par(mfrow = c(3,1)) # Plot the asymptotic distribution of MLE and posterior distribution for n = 10 plot(x_vals, dnorm(x_vals, mean = mean(y_small), sd = mle_sd(y_small)), type = &quot;l&quot;, col = &quot;firebrick&quot;, ylab = &quot;y&quot;, xlab = &quot;x&quot;, main = &quot;n = 10&quot;, ylim = c(0, 1.3)) lines(x_vals, dnorm(x_vals, mean = post_mean(y_small), sd = post_sd(y_small)), col = &quot;navy&quot;) abline(v = 0, lty = 2) # Plot the asymptotic distribution of MLE and posterior distribution for n = 50 plot(x_vals, dnorm(x_vals, mean = mean(y_med), sd = mle_sd(y_med)), type = &quot;l&quot;, col = &quot;firebrick&quot;, ylab = &quot;y&quot;, xlab = &quot;x&quot;, main = &quot;n = 50&quot;) lines(x_vals, dnorm(x_vals, mean = post_mean(y_med), sd = post_sd(y_med)), col = &quot;navy&quot;) abline(v = 0, lty = 2) # Plot the asymptotic distribution of MLE and posterior distribution for n = 100 plot(x_vals, dnorm(x_vals, mean = mean(y_large), sd = mle_sd(y_large)), type = &quot;l&quot;, col = &quot;firebrick&quot;, ylab = &quot;y&quot;, xlab = &quot;x&quot;, main = &quot;n = 100&quot;) lines(x_vals, dnorm(x_vals, mean = post_mean(y_large), sd = post_sd(y_large)), col = &quot;navy&quot;) legend(&quot;bottomleft&quot;, legend = c(&quot;Posterior Distribution&quot;, &quot;MLE Sampling Distribution&quot;), col = c(&quot;navy&quot;, &quot;firebrick&quot;), lty = c(1,1)) abline(v = 0, lty = 2) 3.2.4 Example 2 - Bernoulli-Beta Model In the previous example, we didnt actually need Bernstein-von Mises to get asymptotic normality of the posterior, because the posterior distribution was already normal by definition regardless of how much data we had. Lets look at another example where we can see the posterior getting more normal as we observe more data. Again, we will take advantage of conjugacy for computational convenience. This time, consider observing \\(Y_1, \\dots, Y_n\\) from \\(Bernoulli(p)\\), where the true value of \\(p\\) is 0.5. Bayesian Approach We will use a \\(Beta(1, 5)\\) distribution to take advantage of conjugacy. Then the posterior distribution for \\(p\\) is: \\[\\begin{equation*} p\\mid Y_1,\\dots, Y_n \\sim Beta(1+ \\sum_{i=1}^n Y_i, n+5 - \\sum_{i=1}^n Y_i) \\end{equation*}\\] Frequentist Approach The MLE \\(\\hat p = \\sum_{i=1}^n Y_i/n\\) and the Fisher information is \\(1/p(1-p)\\). The sampling distribution is then \\[\\begin{equation*} \\hat p \\sim N(0.5, \\frac{p(1-p)}{n}) \\end{equation*}\\] p_true &lt;- 0.5 # Functions to calculate the posterior parameters post_alpha &lt;- function(x) { 1+sum(x) } post_beta &lt;- function(x) { n &lt;- length(x) n+5-sum(x) } # Function to calculate asymptotic sd for MLE mle_sd &lt;- function(p, x) { n &lt;- length(x) sqrt(p*(1-p)/n) } # Generate some data of different sample sizes set.seed(2022) y_small &lt;- rbinom(10, size = 1, prob = p_true) y_med &lt;- rbinom(50, size = 1, prob = p_true) y_large &lt;- rbinom(200, size = 1, prob = p_true) # Set up Plotting x_vals &lt;- seq(0, 1, by = 0.01) par(mfrow = c(3,1)) # Plot the asymptotic distribution of MLE and posterior distribution for n = 10 plot(x_vals, dnorm(x_vals, mean = mean(y_small), sd = mle_sd(p_true, y_small)), type = &quot;l&quot;, col = &quot;firebrick&quot;, ylab = &quot;y&quot;, xlab = &quot;x&quot;, main = &quot;n = 10&quot;, ylim = c(0, 3)) lines(x_vals, dbeta(x_vals, shape1 = post_alpha(y_small), shape2 = post_beta(y_small)), col = &quot;navy&quot;) abline(v = p_true, lty = 2) # Plot the asymptotic distribution of MLE and posterior distribution for n = 50 plot(x_vals, dnorm(x_vals, mean = mean(y_med), sd = mle_sd(p_true, y_med)), type = &quot;l&quot;, col = &quot;firebrick&quot;, ylab = &quot;y&quot;, xlab = &quot;x&quot;, main = &quot;n = 50&quot;) lines(x_vals, dbeta(x_vals, shape1 = post_alpha(y_med), shape2 = post_beta(y_med)), col = &quot;navy&quot;) abline(v = p_true, lty = 2) # Plot the asymptotic distribution of MLE and posterior distribution for n = 100 plot(x_vals, dnorm(x_vals, mean = mean(y_large), sd = mle_sd(p_true, y_large)), type = &quot;l&quot;, col = &quot;firebrick&quot;, ylab = &quot;y&quot;, xlab = &quot;x&quot;, main = &quot;n = 200&quot;) lines(x_vals, dbeta(x_vals, shape1 = post_alpha(y_large), shape2 = post_beta(y_large)), col = &quot;navy&quot;) abline(v = p_true, lty = 2) legend(&quot;bottomleft&quot;, legend = c(&quot;Posterior Distribution&quot;, &quot;MLE Sampling Distribution&quot;), col = c(&quot;navy&quot;, &quot;firebrick&quot;), lty = c(1,1)) 3.3 Limitations We do need to be careful with applying Bernstein-von Mises to make sure important assumptions are satisfied! Several of these examples were motivated by this blog post by Dan Simpson which I found entertaining and thought-provoking (Simpson 2017). Here are some examples of when important assumptions of BVM might be violated: The log-likelihood being smooth may be violated in situations were we want to integrate out nuisance parameters, because this can cause spikes in the log likelihood. Our model may not have a fixed number of parameters, for example, in a multi-level model where observing more data may require including more categories and therefore more parameters. Some models have infinite-dimensional parameters, such as models which use non-parametric effects to model unknown functions. The prior may give zero density to the true parameter value - see example 3 \\(\\theta_0\\) may be on the boundary of the parameter space - see example 4 The MLE may not be consistent when the log-likelihood is multimodal, such as in some mixture models. Some other situations where the MLE may not be consistent arise when other assumptions are violated, like the number of parameters increasing with \\(n\\) or the true parameter value being on the boundary of the parameter space. 3.3.1 Other thoughts on consistency Other considerations around consistency which I found interesting are raised by Dan Simpson in his blog post mentioned above. When we consider consistency, we need to consider how the data were collected, and consider what it means to have independent replicates of the same experiment. A lot of datasets are observational, and so there is no guarantee that the data can actually be used to give a consistent estimator of the parameter we want to estimate, regardless of how many times we conduct the experiment. Similarly, collecting a lot of data can take a long time, and over time, the underlying process that we are trying to study may change. This will also present a challenge for consistency. 3.3.2 Example 3 - Prior has zero density at \\(\\theta_0\\) An example of this would be using a uniform prior for a standard deviation and choosing an upper bound which is less than the true standard deviation. For this talk, we wont do an example where the prior gives 0 density to the true value because for these models we would need to use some computational tools tog et the posterior distribution, but we can look at what happens when the prior gives very little density to the true value. Lets return to the first example, where we have collected data from a normal distribution with known variance 1 and we want to estimate its mean. In the first example, we used a prior centred at 0 with variance 1, and the true value happened to be 0. What if the true mean is actually 1000? The prior \\(N(0,1)\\) is now very informative, and will give very little density (but still non-zero) to the true parameter value. Now we have: Bayesian Approach Recall that the posterior is: \\[\\begin{equation*} \\theta \\mid Y_1, \\dots, Y_n \\sim N(\\frac{\\sum_{i=1}^n Y_i}{n+1}, \\frac{1}{n + 1}). \\end{equation*}\\] Frequentist Approach The asymptotic distribution of the MLE is: \\[\\begin{equation*} \\hat \\theta\\sim N(1000, \\frac{1}{n}). \\end{equation*}\\] # Set true param value theta_true &lt;- 1000 # Functions to calculate the posterior mean and sd post_mean &lt;- function(x) { n &lt;- length(x) sum(x)/(n+1) } post_sd &lt;- function(x) { n &lt;- length(x) sqrt(1/(n+1)) } # Function to calculate asymptotic sd for MLE mle_sd &lt;- function(x) { sqrt(1/length(x)) } # Generate some data of different sample sizes set.seed(2022) y_small &lt;- rnorm(10, mean = theta_true, sd = 1) y_med &lt;- rnorm(100, mean = theta_true, sd = 1) y_large &lt;- rnorm(1000, mean = theta_true, sd = 1) # Set up Plotting x_vals &lt;- seq(985, 1001, by = 0.01) par(mfrow = c(3,1)) # Plot the asymptotic distribution of MLE and posterior distribution for n = 10 plot(x_vals, dnorm(x_vals, mean = mean(y_small), sd = mle_sd(y_small)), type = &quot;l&quot;, col = &quot;firebrick&quot;, ylab = &quot;y&quot;, xlab = &quot;x&quot;, main = &quot;n = 10&quot;, ylim = c(0, 1.3)) lines(x_vals, dnorm(x_vals, mean = post_mean(y_small), sd = post_sd(y_small)), col = &quot;navy&quot;) abline(v = theta_true, lty = 2) # Plot the asymptotic distribution of MLE and posterior distribution for n = 100 plot(x_vals, dnorm(x_vals, mean = mean(y_med), sd = mle_sd(y_med)), type = &quot;l&quot;, col = &quot;firebrick&quot;, ylab = &quot;y&quot;, xlab = &quot;x&quot;, main = &quot;n = 100&quot;) lines(x_vals, dnorm(x_vals, mean = post_mean(y_med), sd = post_sd(y_med)), col = &quot;navy&quot;) abline(v = theta_true, lty = 2) # Plot the asymptotic distribution of MLE and posterior distribution for n = 1000 plot(x_vals, dnorm(x_vals, mean = mean(y_large), sd = mle_sd(y_large)), type = &quot;l&quot;, col = &quot;firebrick&quot;, ylab = &quot;y&quot;, xlab = &quot;x&quot;, main = &quot;n = 1000&quot;) lines(x_vals, dnorm(x_vals, mean = post_mean(y_large), sd = post_sd(y_large)), col = &quot;navy&quot;) abline(v = theta_true, lty = 2) legend(&quot;bottomleft&quot;, legend = c(&quot;Posterior Distribution&quot;, &quot;MLE Sampling Distribution&quot;), col = c(&quot;navy&quot;, &quot;firebrick&quot;), lty = c(1,1)) 3.3.3 Example 4 - True parameter value is on the boundary Lets return to the Bernoulli example from before, but this time we will see what happens when the probability is on the boundary, that is, the true value of \\(p = 1\\). Bayesian Approach Recall the posterior distribution for \\(p\\) with a \\(Beta(1, 5)\\) prior is: \\[\\begin{equation*} p\\mid Y_1,\\dots, Y_n \\sim Beta(1+ \\sum_{i=1}^n Y_i, n+5 - \\sum_{i=1}^n Y_i) \\end{equation*}\\] Frequentist Approach The MLE \\(\\hat p = \\sum_{i=1}^n Y_i/n\\) and the Fisher information is \\(1/p(1-p)\\). The sampling distribution is then \\[\\begin{equation*} \\hat p \\sim N(1, 0). \\end{equation*}\\] Note that the variance of the MLEs sampling distribution is now zero, so in other words, it is just a point mass at \\(p=1\\)! Lets see what happens to the posterior. p_true &lt;- 1 # Functions to calculate the posterior mean and sd post_alpha &lt;- function(x) { 1+sum(x) } post_beta &lt;- function(x) { n &lt;- length(x) n+5-sum(x) } # Function to calculate asymptotic sd for MLE mle_sd &lt;- function(p, x) { n &lt;- length(x) sqrt(p*(1-p)/n) } # Generate some data of different sample sizes set.seed(2022) y_small &lt;- rbinom(10, size = 1, prob = p_true) y_med &lt;- rbinom(100, size = 1, prob = p_true) y_large &lt;- rbinom(1000, size = 1, prob = p_true) # Set up Plotting x_vals &lt;- seq(0, 1, by = 0.01) par(mfrow = c(3,1)) # Plot the asymptotic distribution of MLE and posterior distribution for n = 10 plot(x_vals, dbeta(x_vals, shape1 = post_alpha(y_small), shape2 = post_beta(y_small)), col = &quot;navy&quot;, type = &quot;l&quot;, ylab = &quot;y&quot;, xlab = &quot;x&quot;, main = &quot;n = 10&quot;, ylim = c(0, 3)) abline(v = p_true, lty = 2, col = &quot;firebrick&quot;) # Plot the asymptotic distribution of MLE and posterior distribution for n = 50 plot(x_vals, dbeta(x_vals, shape1 = post_alpha(y_med), shape2 = post_beta(y_med)), col = &quot;navy&quot;, type = &quot;l&quot;, ylab = &quot;y&quot;, xlab = &quot;x&quot;, main = &quot;n = 100&quot;) abline(v = p_true, lty = 2, col = &quot;firebrick&quot;) # Plot the asymptotic distribution of MLE and posterior distribution for n = 100 plot(x_vals, dbeta(x_vals, shape1 = post_alpha(y_large), shape2 = post_beta(y_large)), col = &quot;navy&quot;, type = &quot;l&quot;, ylab = &quot;y&quot;, xlab = &quot;x&quot;, main = &quot;n = 1000&quot;) abline(v = p_true, lty = 2, col = &quot;firebrick&quot;) legend(&quot;bottomleft&quot;, legend = c(&quot;Posterior Distribution&quot;, &quot;MLE Sampling Distribution&quot;), col = c(&quot;navy&quot;, &quot;firebrick&quot;), lty = c(1,1)) "],["references.html", "Chapter 4 References", " Chapter 4 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
